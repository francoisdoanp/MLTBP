{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project-ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoisdoanp/MLTBP/blob/master/Project_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "23I2qdWI4FFG"
      },
      "source": [
        "# **Machine learning - Final Project**\n",
        "\n",
        "# Turbofan engine degradation dataset (NASA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nOxT0nXc366_"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "**Importing necessary packages**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J_GboRpW2F6s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c86cf206-6c25-4334-8a79-f182a5ef6d73"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sklearn.metrics as metrics\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qw2HZErj35aM"
      },
      "source": [
        "**Importing the Turbofan engine degradation dataset.**\n",
        "\n",
        "**Files are located in the following Github repository: https://github.com/francoisdoanp/MLTBP**\n",
        "\n",
        "We have 4 training datasets, which contains information about one hundred engines, all of the same type. Thus, we will combine the training and test data sets. \n",
        "\n",
        "The training and test sets have 21 columns: ID, Time (Cycles), 3 columns for operational settings and 21 sensor measurements.\n",
        "\n",
        "The training and testing sets have the same format, while the validation sets only contain the real RUL (remaining useful life).\n",
        "\n",
        "For more information on the data, consult the read me at the following address:https://github.com/francoisdoanp/MLTBP/blob/master/readme.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CmZzDVll4vDW",
        "colab": {}
      },
      "source": [
        "url_base = 'https://raw.githubusercontent.com/francoisdoanp/MLTBP/master/'\n",
        "\n",
        "file_train_1 = 'train_FD001.txt'\n",
        "file_train_2 = 'train_FD002.txt'\n",
        "file_train_3 = 'train_FD003.txt'\n",
        "file_train_4 = 'train_FD004.txt'\n",
        "\n",
        "file_test_1 = 'test_FD001.txt'\n",
        "file_test_2 = 'test_FD002.txt'\n",
        "file_test_3 = 'test_FD003.txt'\n",
        "file_test_4 = 'test_FD004.txt'\n",
        "\n",
        "file_valid_1 = 'RUL_FD001.txt'\n",
        "file_valid_2 = 'RUL_FD002.txt'\n",
        "file_valid_3 = 'RUL_FD003.txt'\n",
        "file_valid_4 = 'RUL_FD004.txt'\n",
        "\n",
        "\n",
        "pt1 = pd.read_csv(url_base + file_train_1, sep=' ', header=None)\n",
        "pt2 = pd.read_csv(url_base + file_train_2, sep=' ', header=None)\n",
        "pt3 = pd.read_csv(url_base + file_train_3, sep=' ', header=None)\n",
        "pt4 = pd.read_csv(url_base + file_train_4, sep=' ', header=None)\n",
        "\n",
        "pte1 = pd.read_csv(url_base + file_test_1, sep=' ', header=None)\n",
        "pte2 = pd.read_csv(url_base + file_test_2, sep=' ', header=None)\n",
        "pte3 = pd.read_csv(url_base + file_test_3, sep=' ', header=None)\n",
        "pte4 = pd.read_csv(url_base + file_test_4, sep=' ', header=None)\n",
        "\n",
        "pv1 = pd.read_csv(url_base + file_valid_1, header=None)\n",
        "pv2 = pd.read_csv(url_base + file_valid_2, header=None)\n",
        "pv3 = pd.read_csv(url_base + file_valid_3, header=None)\n",
        "pv4 = pd.read_csv(url_base + file_valid_4, header=None)\n",
        "\n",
        "\n",
        "# Updating ids\n",
        "\n",
        "pt2[0] = pt2[0].apply(lambda x: x+100)\n",
        "pt3[0] = pt3[0].apply(lambda x: x+360)\n",
        "pt4[0] = pt4[0].apply(lambda x: x+460)\n",
        "\n",
        "pte2[0] = pte2[0].apply(lambda x: x+100)\n",
        "pte3[0] = pte3[0].apply(lambda x: x+359)\n",
        "pte4[0] = pte4[0].apply(lambda x: x+459)\n",
        "\n",
        "\n",
        "# Joining the dataframes\n",
        "\n",
        "train_pd = pd.concat([pt1,pt2,pt3,pt4])\n",
        "test_pd = pd.concat([pte1,pte2,pte3,pte4])\n",
        "valid_pd = pd.concat([pv1,pv2,pv3,pv4], ignore_index=True)\n",
        "\n",
        "train_pd = train_pd.drop(train_pd.columns[[26,27]], axis='columns')\n",
        "test_pd = test_pd.drop(test_pd.columns[[26,27]], axis='columns')\n",
        "\n",
        "\n",
        "# Assigning labels to Dataframe's columns based on the Readme\n",
        "\n",
        "train_pd.columns = ['id', 'Time (Cycles)', 'OS1', 'OS2', 'OS3', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21']\n",
        "test_pd.columns = ['id', 'Time (Cycles)', 'OS1', 'OS2', 'OS3', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21']\n",
        "valid_pd.columns = ['RUL']\n",
        "\n",
        "#Loading scaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G9va4qroPgeB"
      },
      "source": [
        "**Adding variables Conditons and fault mode**\n",
        "\n",
        "Note:\n",
        "\n",
        "**Condition (ONE)** and **Fault ONE** are binary variables.\n",
        "\n",
        "When Condition(ONE) = 1 (true), it means that the condition is at Sea Level\n",
        "\n",
        "When Condition(ONE) = 0 (false), it means NO, the condition IS NOT AT SEA LEVEL, and thus is the  second condition; SIX.\n",
        "\n",
        "When Fault ONE = 1 (true), it means that the fault modes is one (HPC Degradation)\n",
        "\n",
        "When Fault ONE = 0 (false), it means that the fault mode is TWO (HPC Degradation and Fan degradation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_WQaAK97PfZU",
        "outputId": "bbfb1aa7-9981-4873-ad1b-153b96000ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Adding variables Condition and fault modes\n",
        "\n",
        "def value_condition_train(row):\n",
        "  if (row['id'] <= 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 360) & (row['id'] > 100):\n",
        "    return 0\n",
        "  elif (row['id'] <= 460) & (row['id'] > 360):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_fault_train(row):\n",
        "  if (row['id'] <= 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 360) & (row['id'] > 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 460) & (row['id'] > 360):\n",
        "    return 0\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_condition_test(row):\n",
        "  if (row['id'] <= 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 359) & (row['id'] > 100):\n",
        "    return 0\n",
        "  elif (row['id'] <= 459) & (row['id'] > 359):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_fault_test(row):\n",
        "  if (row['id'] <= 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 359) & (row['id'] > 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 459) & (row['id'] > 359):\n",
        "    return 0\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "train_pd['Condition (One)'] = train_pd.apply(value_condition_train, axis=1)\n",
        "train_pd['Fault ONE'] = train_pd.apply(value_fault_train,axis=1)\n",
        "\n",
        "test_pd['Condition (One)'] = test_pd.apply(value_condition_test, axis=1)\n",
        "test_pd['Fault ONE'] = test_pd.apply(value_fault_test,axis=1)\n",
        "\n",
        "display(train_pd)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Time (Cycles)</th>\n",
              "      <th>OS1</th>\n",
              "      <th>OS2</th>\n",
              "      <th>OS3</th>\n",
              "      <th>S1</th>\n",
              "      <th>S2</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>S5</th>\n",
              "      <th>S6</th>\n",
              "      <th>S7</th>\n",
              "      <th>S8</th>\n",
              "      <th>S9</th>\n",
              "      <th>S10</th>\n",
              "      <th>S11</th>\n",
              "      <th>S12</th>\n",
              "      <th>S13</th>\n",
              "      <th>S14</th>\n",
              "      <th>S15</th>\n",
              "      <th>S16</th>\n",
              "      <th>S17</th>\n",
              "      <th>S18</th>\n",
              "      <th>S19</th>\n",
              "      <th>S20</th>\n",
              "      <th>S21</th>\n",
              "      <th>Condition (One)</th>\n",
              "      <th>Fault ONE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61244</th>\n",
              "      <td>709</td>\n",
              "      <td>251</td>\n",
              "      <td>9.9998</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.33</td>\n",
              "      <td>1516.36</td>\n",
              "      <td>1315.28</td>\n",
              "      <td>10.52</td>\n",
              "      <td>15.46</td>\n",
              "      <td>404.59</td>\n",
              "      <td>2319.66</td>\n",
              "      <td>8840.16</td>\n",
              "      <td>1.27</td>\n",
              "      <td>46.08</td>\n",
              "      <td>380.16</td>\n",
              "      <td>2388.73</td>\n",
              "      <td>8185.69</td>\n",
              "      <td>8.4541</td>\n",
              "      <td>0.03</td>\n",
              "      <td>372</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.0</td>\n",
              "      <td>29.11</td>\n",
              "      <td>17.5234</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61245</th>\n",
              "      <td>709</td>\n",
              "      <td>252</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1598.92</td>\n",
              "      <td>1426.77</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.57</td>\n",
              "      <td>567.59</td>\n",
              "      <td>2388.47</td>\n",
              "      <td>9117.12</td>\n",
              "      <td>1.31</td>\n",
              "      <td>48.04</td>\n",
              "      <td>535.02</td>\n",
              "      <td>2388.46</td>\n",
              "      <td>8185.47</td>\n",
              "      <td>8.2221</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.38</td>\n",
              "      <td>23.7151</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61246</th>\n",
              "      <td>709</td>\n",
              "      <td>253</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.68</td>\n",
              "      <td>1607.72</td>\n",
              "      <td>1430.56</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.57</td>\n",
              "      <td>569.04</td>\n",
              "      <td>2388.51</td>\n",
              "      <td>9126.53</td>\n",
              "      <td>1.31</td>\n",
              "      <td>48.24</td>\n",
              "      <td>535.41</td>\n",
              "      <td>2388.48</td>\n",
              "      <td>8193.94</td>\n",
              "      <td>8.2525</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.78</td>\n",
              "      <td>23.8270</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61247</th>\n",
              "      <td>709</td>\n",
              "      <td>254</td>\n",
              "      <td>35.0046</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.77</td>\n",
              "      <td>1381.29</td>\n",
              "      <td>1148.18</td>\n",
              "      <td>5.48</td>\n",
              "      <td>7.96</td>\n",
              "      <td>199.93</td>\n",
              "      <td>2223.78</td>\n",
              "      <td>8403.64</td>\n",
              "      <td>1.05</td>\n",
              "      <td>42.53</td>\n",
              "      <td>187.92</td>\n",
              "      <td>2388.83</td>\n",
              "      <td>8125.64</td>\n",
              "      <td>9.0515</td>\n",
              "      <td>0.02</td>\n",
              "      <td>337</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.0</td>\n",
              "      <td>15.26</td>\n",
              "      <td>9.0774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61248</th>\n",
              "      <td>709</td>\n",
              "      <td>255</td>\n",
              "      <td>42.0030</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.85</td>\n",
              "      <td>1369.75</td>\n",
              "      <td>1147.45</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.69</td>\n",
              "      <td>142.47</td>\n",
              "      <td>2212.52</td>\n",
              "      <td>8391.31</td>\n",
              "      <td>1.05</td>\n",
              "      <td>42.60</td>\n",
              "      <td>134.32</td>\n",
              "      <td>2388.66</td>\n",
              "      <td>8144.33</td>\n",
              "      <td>9.1207</td>\n",
              "      <td>0.02</td>\n",
              "      <td>333</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.66</td>\n",
              "      <td>6.4341</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160359 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  Time (Cycles)      OS1  ...      S21  Condition (One)  Fault ONE\n",
              "0        1              1  -0.0007  ...  23.4190                1          1\n",
              "1        1              2   0.0019  ...  23.4236                1          1\n",
              "2        1              3  -0.0043  ...  23.3442                1          1\n",
              "3        1              4   0.0007  ...  23.3739                1          1\n",
              "4        1              5  -0.0019  ...  23.4044                1          1\n",
              "...    ...            ...      ...  ...      ...              ...        ...\n",
              "61244  709            251   9.9998  ...  17.5234                0          0\n",
              "61245  709            252   0.0028  ...  23.7151                0          0\n",
              "61246  709            253   0.0029  ...  23.8270                0          0\n",
              "61247  709            254  35.0046  ...   9.0774                0          0\n",
              "61248  709            255  42.0030  ...   6.4341                0          0\n",
              "\n",
              "[160359 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lAl6DjVwhdhU"
      },
      "source": [
        "At this stage, we create the truth remaining useful life (RUL) for the training set.\n",
        "\n",
        "Important note: In the training set, the last Cycle (represented in the table by 'Time (Cycles)') is when the engine is considered unusable. However, in the test set, the last cycle IS NOT when the engine is considered unusable. It will fail at a later time. Thus, in the valid_pd, we have the true RUL. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UdbuXXApd51H",
        "colab": {}
      },
      "source": [
        "#Adding column for remaining useful life (RUL)\n",
        "\n",
        "y_train = pd.DataFrame(train_pd.groupby(['id'])['Time (Cycles)'].max())\n",
        "\n",
        "train_pd = pd.merge(train_pd,y_train, on='id')\n",
        "train_pd['RUL'] = train_pd['Time (Cycles)_y'] - train_pd['Time (Cycles)_x']\n",
        "train_pd = train_pd.drop('Time (Cycles)_y',1)\n",
        "train_pd = train_pd.rename(columns = {'Time (Cycles)_x':'Time (Cycles)'})\n",
        "\n",
        "y_train = train_pd.iloc[:,28]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vhz30Roasqsx",
        "colab": {}
      },
      "source": [
        "def model_score(y_true, y_pred):\n",
        "  pred_df = pd.DataFrame(y_pred)\n",
        "  test_err = pd.concat([y_true,pred_df], axis=1)\n",
        "  test_err.columns = ['RUL', 'Pred_RUL']\n",
        "  a1 = 10\n",
        "  a2 = 13\n",
        "  score=0\n",
        "\n",
        "  for index, row in test_err.iterrows():\n",
        "    d = row['Pred_RUL'] - row['RUL']\n",
        "    if d < 0:\n",
        "      score += np.expm1(-(d/a1))\n",
        "    else:\n",
        "      score += np.expm1(d/a2)\n",
        "\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IBSnn8dg_S-f"
      },
      "source": [
        "\n",
        "# Data Exploration\n",
        "\n",
        "**Now that we have our data, we can get to know our dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLyYj7yG_O7J",
        "colab": {}
      },
      "source": [
        "display(train_pd.head())\n",
        "\n",
        "display(test_pd)\n",
        "\n",
        "\n",
        "print(f'The training dataset contains {train_pd.shape[0]} rows.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MolsPcwA8oH2",
        "colab": {}
      },
      "source": [
        "# Print out a table with count, mean, std, min, max, 25%, 50%, 75%\n",
        "\n",
        "print(train_pd.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9NjbN8Ul_QA"
      },
      "source": [
        "**Exploring the effects of sensors on RUL**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5gRZJbxko0zO",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "print(sns.heatmap(train_pd.corr(), annot=True, cmap='RdYlGn'))\n",
        "\n",
        "train_pd.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kg9ioWTZpt4c",
        "colab": {}
      },
      "source": [
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xk-xi71-oicW"
      },
      "source": [
        "**Exploring correlation between variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vqocxW0Qohvj",
        "colab": {}
      },
      "source": [
        "corr = train_pd.groupby(['RUL']).corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rd8Y35kaDfly"
      },
      "source": [
        "**How do we know when an engine fails?**\n",
        "\n",
        "We look at the last time cycle for every id.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uVn0ZdmKDsb0",
        "colab": {}
      },
      "source": [
        "train_pd.groupby(['id'])['Time (Cycles)'].max().hist(bins=30, grid=False)\n",
        "plt.xlabel('Number of Cycles')\n",
        "plt.ylabel('Frequency')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n-7vUK4u85DO"
      },
      "source": [
        "#**Model 1: Multiple Linear Regression**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-mn7nZq39QVV"
      },
      "source": [
        "**Preparing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSvBTo9285u0",
        "colab": {}
      },
      "source": [
        "# Scaling data\n",
        "\n",
        "train_pd_scaled = train_pd.copy()\n",
        "train_pd_scaled.iloc[:,2:26] = scaler.fit_transform(train_pd.iloc[:,2:26])\n",
        "\n",
        "test_pd_scaled = test_pd.copy()\n",
        "test_pd_scaled.iloc[:,2:26] = scaler.fit_transform(test_pd.iloc[:,2:26])\n",
        "\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.max_colwidth', -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ENkana6AH9LA",
        "colab": {}
      },
      "source": [
        "# Removing RUL and id columns, as we do not want these features to be in our predictors\n",
        "\n",
        "train_pd_lm = train_pd_scaled.copy()\n",
        "train_pd_lm = train_pd_lm.drop(['id', 'RUL'],axis=1)\n",
        "\n",
        "# Keeping only last time cycle for each id\n",
        "\n",
        "idx = test_pd_scaled.groupby(['id'])['Time (Cycles)'].transform(max) == test_pd_scaled['Time (Cycles)']\n",
        "test_pd_lm = test_pd_scaled[idx]\n",
        "\n",
        "# Removing id column\n",
        "\n",
        "test_pd_lm = test_pd_lm.drop(['id'], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1taB9Kg6Nz_P"
      },
      "source": [
        "**Fitting Linear Model (Not time sensitive)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FvtozoRK9Xxj",
        "outputId": "e7e20b2b-0f49-4a66-80a4-ab60aad610e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Fitting Linear model\n",
        "\n",
        "reg = LinearRegression().fit(train_pd_lm, y_train)\n",
        "\n",
        "y_pred = reg.predict(test_pd_lm)\n",
        "\n",
        "acc_score_lm =  metrics.mean_absolute_error(valid_pd, y_pred)\n",
        "\n",
        "print(f'The mean absolute error for the linear model is: {(acc_score_lm)}.')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean absolute error for the linear model is: 44.965450059476375.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx7pJ2iVgTwi",
        "colab_type": "text"
      },
      "source": [
        "**Linear Model with interactions & Polynomial**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0rRYfxNhg3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The PolynomialFeatures transforms our dataset to include ALL interactions and ALL variables^2.\n",
        "\n",
        "lm_poly_int = PolynomialFeatures(2)\n",
        "train_pd_lm_poly = lm_poly_int.fit_transform(train_pd_lm)\n",
        "\n",
        "reg_poly = LinearRegression().fit(train_pd_lm_poly,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSJhNHznjrlb",
        "colab_type": "code",
        "outputId": "92807f6d-afb9-4a29-ad91-03e0bb9e0b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test_pd_lm_poly = lm_poly_int.fit_transform(test_pd_lm)\n",
        "\n",
        "y_pred_poly = reg_poly.predict(test_pd_lm_poly)\n",
        "\n",
        "acc_score_lm_poly =  metrics.mean_absolute_error(valid_pd, y_pred_poly)\n",
        "\n",
        "print(f'The mean absolute error for the linear model is: {(acc_score_lm_poly)}.')\n",
        "\n",
        "# We conclude that there is probabily high colinearity in the variables, so a model including interactions would not help much."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean absolute error for the linear model is: 6690.860898272314.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhYn-0V5kSw9",
        "colab_type": "text"
      },
      "source": [
        "# **Model 3: Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFTyU01LH4SK",
        "colab_type": "text"
      },
      "source": [
        "# **Model 3.1: Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvWvliCAHwKT",
        "colab_type": "code",
        "outputId": "42ae9d25-ef85-4a4e-f0e9-d3aaf2159ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Building Model\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(100,  activation='relu', input_shape=[len(train_pd_lm.keys())], kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01),  activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "model2.add(Dense(1))\n",
        "\n",
        "model2.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "\n",
        "print(model2.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 100)               2800      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 103,901\n",
            "Trainable params: 103,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2XwNbZeKOlv",
        "colab_type": "code",
        "outputId": "050f5be3-14aa-4871-d90b-b5c774016676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "# Fitting model\n",
        "\n",
        "NNmodel2 = model2.fit(train_pd_lm, y_train, epochs=100, batch_size=200, validation_split=0.05, verbose=1,callbacks =[keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='min')])\n",
        "#NNmodel2 = model2.fit(train_pd_lm, y_train, epochs=10, batch_size=200, validation_split=0.05, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 152341 samples, validate on 8018 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "152341/152341 [==============================] - 7s 44us/step - loss: 11343.9187 - mean_absolute_error: 54.6589 - val_loss: 4890.9898 - val_mean_absolute_error: 45.7493\n",
            "Epoch 2/100\n",
            "152341/152341 [==============================] - 5s 35us/step - loss: 4599.2780 - mean_absolute_error: 44.2124 - val_loss: 3734.7898 - val_mean_absolute_error: 42.7269\n",
            "Epoch 3/100\n",
            "152341/152341 [==============================] - 5s 36us/step - loss: 4003.7893 - mean_absolute_error: 42.5907 - val_loss: 3607.4716 - val_mean_absolute_error: 40.2314\n",
            "Epoch 4/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 3703.5752 - mean_absolute_error: 41.4244 - val_loss: 2840.2736 - val_mean_absolute_error: 37.3040\n",
            "Epoch 5/100\n",
            "152341/152341 [==============================] - 6s 36us/step - loss: 3468.0501 - mean_absolute_error: 40.3535 - val_loss: 2708.3388 - val_mean_absolute_error: 36.1539\n",
            "Epoch 6/100\n",
            "152341/152341 [==============================] - 5s 36us/step - loss: 3299.8889 - mean_absolute_error: 39.4915 - val_loss: 4070.1379 - val_mean_absolute_error: 49.8754\n",
            "Epoch 7/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 3163.3246 - mean_absolute_error: 38.7880 - val_loss: 2856.0439 - val_mean_absolute_error: 40.3800\n",
            "Epoch 8/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 3053.5356 - mean_absolute_error: 38.1218 - val_loss: 2512.2213 - val_mean_absolute_error: 35.8135\n",
            "Epoch 9/100\n",
            "152341/152341 [==============================] - 6s 39us/step - loss: 2967.4610 - mean_absolute_error: 37.6305 - val_loss: 2596.6247 - val_mean_absolute_error: 35.5065\n",
            "Epoch 10/100\n",
            "152341/152341 [==============================] - 5s 35us/step - loss: 2898.2215 - mean_absolute_error: 37.2347 - val_loss: 2434.5657 - val_mean_absolute_error: 34.9000\n",
            "Epoch 11/100\n",
            "152341/152341 [==============================] - 5s 36us/step - loss: 2821.4304 - mean_absolute_error: 36.7595 - val_loss: 3389.9256 - val_mean_absolute_error: 45.3032\n",
            "Epoch 12/100\n",
            "152341/152341 [==============================] - 6s 38us/step - loss: 2794.8978 - mean_absolute_error: 36.5732 - val_loss: 2403.0128 - val_mean_absolute_error: 35.9568\n",
            "Epoch 13/100\n",
            "152341/152341 [==============================] - 7s 46us/step - loss: 2744.2744 - mean_absolute_error: 36.2629 - val_loss: 2415.6785 - val_mean_absolute_error: 35.6823\n",
            "Epoch 14/100\n",
            "152341/152341 [==============================] - 7s 48us/step - loss: 2707.6799 - mean_absolute_error: 35.9978 - val_loss: 2538.5202 - val_mean_absolute_error: 36.5636\n",
            "Epoch 15/100\n",
            "152341/152341 [==============================] - 7s 43us/step - loss: 2676.1283 - mean_absolute_error: 35.8269 - val_loss: 2431.9416 - val_mean_absolute_error: 37.1914\n",
            "Epoch 16/100\n",
            "152341/152341 [==============================] - 8s 49us/step - loss: 2637.3914 - mean_absolute_error: 35.6134 - val_loss: 2411.2771 - val_mean_absolute_error: 36.0599\n",
            "Epoch 17/100\n",
            "152341/152341 [==============================] - 6s 41us/step - loss: 2611.2713 - mean_absolute_error: 35.4342 - val_loss: 4629.5318 - val_mean_absolute_error: 57.4732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hdTP9_aEFRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "233220de-7dbb-4175-f957-1274e846c8fc"
      },
      "source": [
        "# Testing on validation set\n",
        "\n",
        "y_pred_nn = model2.predict(test_pd_lm, batch_size=20, verbose=1)\n",
        "\n",
        "result_nn = metrics.mean_absolute_error(y_pred_nn, valid_pd)\n",
        "\n",
        "print(f'The mean absoute error of the Neural Network on the test test is {result_nn}.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "707/707 [==============================] - 0s 321us/step\n",
            "The mean absoute error of the Neural Network on the test test is 37.63172954683425.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4atglFkEHw50",
        "colab_type": "text"
      },
      "source": [
        "# **Model 3.2: Neural Network with LSTM architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YhFj4atfNtGW",
        "outputId": "3d4deea2-0b15-47e2-ab15-a36ffb47c891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Using Azure tutorial for predictive maintenance for data manipulation\n",
        "# Reference: https://github.com/Azure/lstms_for_predictive_maintenance/blob/master/Deep%20Learning%20Basics%20for%20Predictive%20Maintenance.ipynb\n",
        "\n",
        "# Picking a sequence length - This will be the window of time in which the LSTM will gather data from\n",
        "\n",
        "sequence_length = 25\n",
        "\n",
        "\n",
        "# This function will reshape our data so it can be usable with Keras (Samples, time window, features)\n",
        "def gen_sequence(id_df, seq_length,seq_cols):\n",
        "  data_array = id_df[seq_cols].values\n",
        "  num_elements = data_array.shape[0]\n",
        "  for start,stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "    yield data_array[start:stop,:]\n",
        "\n",
        "# Reference column names\n",
        "\n",
        "sensor_cols = ['S' + str(i) for i in range(1,22)]\n",
        "sequence_cols = ['Time (Cycles)', 'OS1', 'OS2', 'OS3']\n",
        "other_cols = ['Condition (One)', 'Fault ONE']\n",
        "sequence_cols.extend(sensor_cols)\n",
        "sequence_cols.extend(other_cols)\n",
        "\n",
        "# Generating sequences\n",
        "\n",
        "seq_gen = (list(gen_sequence(train_pd_scaled[train_pd_scaled['id']==id], sequence_length,sequence_cols))\n",
        "          for id in train_pd_scaled['id'].unique())\n",
        "\n",
        "# Generate sequences and convert to numpy array\n",
        "\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "print(seq_array.shape)\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "  data = id_df[label].values\n",
        "  num_elements = data.shape[0]\n",
        "  return data[seq_length:num_elements,:]\n",
        "\n",
        "label_gen = [gen_labels(train_pd_scaled[train_pd_scaled['id']==id], sequence_length, ['RUL'])\n",
        "            for id in train_pd_scaled['id'].unique()]\n",
        "\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "print(label_array.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(142634, 25, 27)\n",
            "(142634, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7CzDE0PV9a0",
        "colab_type": "code",
        "outputId": "ace83013-59f5-47a8-a68e-1ae4e24ad313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# Building the RNN\n",
        "\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(input_shape=(sequence_length, nb_features), units=100, return_sequences=True))\n",
        "model.add(LSTM(units=150, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=200, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=100, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(1, return_sequences=True))\n",
        "\n",
        "\n",
        "#model.add(LSTM(input_shape=(sequence_length, nb_features), units=50, return_sequences=False))\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "#model.add(Dense(units=nb_out))\n",
        "#model.add(Activation('linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_35 (LSTM)               (None, 25, 100)           51200     \n",
            "_________________________________________________________________\n",
            "lstm_36 (LSTM)               (None, 25, 150)           150600    \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 25, 150)           0         \n",
            "_________________________________________________________________\n",
            "lstm_37 (LSTM)               (None, 25, 200)           280800    \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 25, 200)           0         \n",
            "_________________________________________________________________\n",
            "lstm_38 (LSTM)               (None, 25, 100)           120400    \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 25, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_39 (LSTM)               (None, 25, 50)            30200     \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 25, 50)            0         \n",
            "_________________________________________________________________\n",
            "lstm_40 (LSTM)               (None, 25, 1)             208       \n",
            "=================================================================\n",
            "Total params: 633,408\n",
            "Trainable params: 633,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhCTv_y1dYxz",
        "colab_type": "code",
        "outputId": "b6b2ae0d-0e58-4499-d90d-b51b4288bca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        }
      },
      "source": [
        "# Fitting the RNN\n",
        "\n",
        "model.fit(seq_array, label_array, epochs=100, batch_size=50, validation_split=0.05, verbose=1, callbacks =[keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-edc09d616953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected lstm_40 to have 3 dimensions, but got array with shape (142634, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWRJI83J1R67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding RUL to test set\n",
        "\n",
        "truth_nn= valid_pd.copy()\n",
        "max_hid = pd.DataFrame(test_pd.groupby('id')['Time (Cycles)'].max()).reset_index()\n",
        "max_hid.columns = ['id','max']\n",
        "truth_nn.columns = ['truth']\n",
        "truth_nn['id'] = truth_nn.index +1\n",
        "truth_nn['truth'] = truth_nn['truth'] + max_hid['max']\n",
        "\n",
        "test_pd_nn = test_pd.copy()\n",
        "test_pd_nn = test_pd_nn.merge(truth_nn, on=['id'], how='left')\n",
        "test_pd_nn['RUL'] = test_pd_nn['truth'] - test_pd_nn['Time (Cycles)']\n",
        "test_pd_nn.drop('truth', axis=1, inplace=True)\n",
        "\n",
        "print(test_pd_nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCjYCkhVvv_i",
        "colab_type": "code",
        "outputId": "cece804f-6958-41eb-b7d6-656deb256e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Preparing test set\n",
        "\n",
        "seq_array_test = [test_pd_nn[test_pd_nn['id']==id][sequence_cols].values[-sequence_length:]\n",
        "                 for id in test_pd_nn['id'].unique() if len(test_pd_nn[test_pd_nn['id']==id]) >= sequence_length]\n",
        "\n",
        "seq_array_test = np.asarray(seq_array_test).astype(np.float32)\n",
        "\n",
        "y_mask = [len(test_pd_nn[test_pd_nn['id']==id]) >= sequence_length for id in test_pd_nn['id'].unique()]\n",
        "\n",
        "label_array_test = test_pd_nn.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
        "label_array_test = label_array_test.reshape(label_array_test.shape[0],1).astype(np.float32)\n",
        "\n",
        "print(seq_array_test.shape)\n",
        "print(label_array_test.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(697, 25, 27)\n",
            "(697, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27TmEvu6E0lz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1ab1ecfa-6e9d-4738-9cd5-af372a843313"
      },
      "source": [
        "# Fitting model on test set\n",
        "\n",
        "y_pred_lstm = model.predict(seq_array_test, batch_size=50, verbose=1)\n",
        "\n",
        "result_lstm =  metrics.mean_absolute_error(y_pred_lstm, label_array_test)\n",
        "\n",
        "print(f'The mean absolute error for the LSTM on the test set is {result_lstm}.' )\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "697/697 [==============================] - 1s 1ms/step\n",
            "The mean absolute error for the LSTM on the test set is 46.81201934814453.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}