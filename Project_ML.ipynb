{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project-ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoisdoanp/MLTBP/blob/master/Project_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23I2qdWI4FFG",
        "colab_type": "text"
      },
      "source": [
        "# **Machine learning - Final Project**\n",
        "\n",
        "# Turbofan engine degradation dataset (NASA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOxT0nXc366_",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "**Importing necessary packages**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_GboRpW2F6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sklearn.metrics as metrics\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw2HZErj35aM",
        "colab_type": "text"
      },
      "source": [
        "**Importing the Turbofan engine degradation dataset.**\n",
        "\n",
        "**Files are located in the following Github repository: https://github.com/francoisdoanp/MLTBP**\n",
        "\n",
        "We have 4 training datasets, which contains information about one hundred engines, all of the same type. Thus, we will combine the training and test data sets. \n",
        "\n",
        "The training and test sets have 21 columns: ID, Time (Cycles), 3 columns for operational settings and 21 sensor measurements.\n",
        "\n",
        "The training and testing sets have the same format, while the validation sets only contain the real RUL (remaining useful life).\n",
        "\n",
        "For more information on the data, consult the read me at the following address:https://github.com/francoisdoanp/MLTBP/blob/master/readme.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmZzDVll4vDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_base = 'https://raw.githubusercontent.com/francoisdoanp/MLTBP/master/'\n",
        "\n",
        "file_train_1 = 'train_FD001.txt'\n",
        "file_train_2 = 'train_FD002.txt'\n",
        "file_train_3 = 'train_FD003.txt'\n",
        "file_train_4 = 'train_FD004.txt'\n",
        "\n",
        "file_test_1 = 'test_FD001.txt'\n",
        "file_test_2 = 'test_FD002.txt'\n",
        "file_test_3 = 'test_FD003.txt'\n",
        "file_test_4 = 'test_FD004.txt'\n",
        "\n",
        "file_valid_1 = 'RUL_FD001.txt'\n",
        "file_valid_2 = 'RUL_FD002.txt'\n",
        "file_valid_3 = 'RUL_FD003.txt'\n",
        "file_valid_4 = 'RUL_FD004.txt'\n",
        "\n",
        "\n",
        "pt1 = pd.read_csv(url_base + file_train_1, sep=' ', header=None)\n",
        "pt2 = pd.read_csv(url_base + file_train_2, sep=' ', header=None)\n",
        "pt3 = pd.read_csv(url_base + file_train_3, sep=' ', header=None)\n",
        "pt4 = pd.read_csv(url_base + file_train_4, sep=' ', header=None)\n",
        "\n",
        "pte1 = pd.read_csv(url_base + file_test_1, sep=' ', header=None)\n",
        "pte2 = pd.read_csv(url_base + file_test_2, sep=' ', header=None)\n",
        "pte3 = pd.read_csv(url_base + file_test_3, sep=' ', header=None)\n",
        "pte4 = pd.read_csv(url_base + file_test_4, sep=' ', header=None)\n",
        "\n",
        "pv1 = pd.read_csv(url_base + file_valid_1, header=None)\n",
        "pv2 = pd.read_csv(url_base + file_valid_2, header=None)\n",
        "pv3 = pd.read_csv(url_base + file_valid_3, header=None)\n",
        "pv4 = pd.read_csv(url_base + file_valid_4, header=None)\n",
        "\n",
        "\n",
        "# Updating unit numbers\n",
        "\n",
        "pt2[0] = pt2[0].apply(lambda x: x+100)\n",
        "pt3[0] = pt3[0].apply(lambda x: x+360)\n",
        "pt4[0] = pt4[0].apply(lambda x: x+460)\n",
        "\n",
        "pte2[0] = pte2[0].apply(lambda x: x+100)\n",
        "pte3[0] = pte3[0].apply(lambda x: x+359)\n",
        "pte4[0] = pte4[0].apply(lambda x: x+459)\n",
        "\n",
        "\n",
        "# Joining the dataframes\n",
        "\n",
        "train_pd = pd.concat([pt1,pt2,pt3,pt4])\n",
        "test_pd = pd.concat([pte1,pte2,pte3,pte4])\n",
        "valid_pd = pd.concat([pv1,pv2,pv3,pv4], ignore_index=True)\n",
        "\n",
        "train_pd = train_pd.drop(train_pd.columns[[26,27]], axis='columns')\n",
        "test_pd = test_pd.drop(test_pd.columns[[26,27]], axis='columns')\n",
        "\n",
        "\n",
        "# Assigning labels to Dataframe's columns based on the Readme\n",
        "\n",
        "train_pd.columns = ['Unit Number', 'Time (Cycles)', 'OS1', 'OS2', 'OS3', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21']\n",
        "test_pd.columns = ['Unit Number', 'Time (Cycles)', 'OS1', 'OS2', 'OS3', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21']\n",
        "valid_pd.columns = ['RUL']\n",
        "\n",
        "#Loading scaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9va4qroPgeB",
        "colab_type": "text"
      },
      "source": [
        "**Adding variables Conditons and fault mode**\n",
        "\n",
        "Note:\n",
        "\n",
        "**Condition (ONE)** and **Fault ONE** are binary variables.\n",
        "\n",
        "When Condition(ONE) = 1 (true), it means that the condition is at Sea Level\n",
        "\n",
        "When Condition(ONE) = 0 (false), it means NO, the condition IS NOT AT SEA LEVEL, and thus is the  second condition; SIX.\n",
        "\n",
        "When Fault ONE = 1 (true), it means that the fault modes is one (HPC Degradation)\n",
        "\n",
        "When Fault ONE = 0 (false), it means that the fault mode is TWO (HPC Degradation and Fan degradation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WQaAK97PfZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding variables Condition and fault modes\n",
        "\n",
        "def value_condition_train(row):\n",
        "  if (row['Unit Number'] <= 100):\n",
        "    return 1\n",
        "  elif (row['Unit Number'] <= 360) & (row['Unit Number'] > 100):\n",
        "    return 0\n",
        "  elif (row['Unit Number'] <= 460) & (row['Unit Number'] > 360):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_fault_train(row):\n",
        "  if (row['Unit Number'] <= 100):\n",
        "    return 1\n",
        "  elif (row['Unit Number'] <= 360) & (row['Unit Number'] > 100):\n",
        "    return 1\n",
        "  elif (row['Unit Number'] <= 460) & (row['Unit Number'] > 360):\n",
        "    return 0\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_condition_test(row):\n",
        "  if (row['Unit Number'] <= 100):\n",
        "    return 1\n",
        "  elif (row['Unit Number'] <= 359) & (row['Unit Number'] > 100):\n",
        "    return 0\n",
        "  elif (row['Unit Number'] <= 459) & (row['Unit Number'] > 359):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_fault_test(row):\n",
        "  if (row['Unit Number'] <= 100):\n",
        "    return 1\n",
        "  elif (row['Unit Number'] <= 359) & (row['Unit Number'] > 100):\n",
        "    return 1\n",
        "  elif (row['Unit Number'] <= 459) & (row['Unit Number'] > 359):\n",
        "    return 0\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "train_pd['Condition (One)'] = train_pd.apply(value_condition_train, axis=1)\n",
        "train_pd['Fault ONE'] = train_pd.apply(value_fault_train,axis=1)\n",
        "\n",
        "test_pd['Condition (One)'] = test_pd.apply(value_condition_test, axis=1)\n",
        "test_pd['Fault ONE'] = test_pd.apply(value_fault_test,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAl6DjVwhdhU",
        "colab_type": "text"
      },
      "source": [
        "At this stage, we create the truth remaining useful life (RUL) for the training set.\n",
        "\n",
        "Important note: In the training set, the last Cycle (represented in the table by 'Time (Cycles)') is when the engine is considered unusable. However, in the test set, the last cycle IS NOT when the engine is considered unusable. It will fail at a later time. Thus, in the valid_pd, we have the true RUL. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdbuXXApd51H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Adding column for remaining useful life (RUL)\n",
        "\n",
        "y_train = pd.DataFrame(train_pd.groupby(['Unit Number'])['Time (Cycles)'].max())\n",
        "\n",
        "train_pd = pd.merge(train_pd,y_train, on='Unit Number')\n",
        "train_pd['RUL'] = train_pd['Time (Cycles)_y'] - train_pd['Time (Cycles)_x']\n",
        "train_pd = train_pd.drop('Time (Cycles)_y',1)\n",
        "train_pd = train_pd.rename(columns = {'Time (Cycles)_x':'Time (Cycles)'})\n",
        "\n",
        "y_train = train_pd.iloc[:,28]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhz30Roasqsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjusted_error(y_true, y_pred):\n",
        "  pred_df = pd.DataFrame(y_pred)\n",
        "  test_err = pd.concat([y_true,pred_df], axis=1)\n",
        "  test_err.columns = ['RUL', 'Pred_RUL']\n",
        "  a1 = 10\n",
        "  a2 = 13\n",
        "  score=0\n",
        "\n",
        "  for index, row in test_err.iterrows():\n",
        "    d = row['Pred_RUL'] - row['RUL']\n",
        "    if d < 0:\n",
        "      score += np.expm1(-(d/a1))\n",
        "    else:\n",
        "      score += np.expm1(d/a2)\n",
        "\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBSnn8dg_S-f",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Data Exploration\n",
        "\n",
        "**Now that we have our data, we can get to know our dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLyYj7yG_O7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(train_pd.head())\n",
        "\n",
        "display(test_pd)\n",
        "\n",
        "\n",
        "print(f'The training dataset contains {train_pd.shape[0]} rows.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MolsPcwA8oH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print out a table with count, mean, std, min, max, 25%, 50%, 75%\n",
        "\n",
        "print(train_pd.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9NjbN8Ul_QA",
        "colab_type": "text"
      },
      "source": [
        "**Exploring the effects of sensors on RUL**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gRZJbxko0zO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "print(sns.heatmap(train_pd.corr(), annot=True, cmap='RdYlGn'))\n",
        "\n",
        "train_pd.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg9ioWTZpt4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk-xi71-oicW",
        "colab_type": "text"
      },
      "source": [
        "**Exploring correlation between variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqocxW0Qohvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = train_pd.groupby(['RUL']).corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd8Y35kaDfly",
        "colab_type": "text"
      },
      "source": [
        "**How do we know when an engine fails?**\n",
        "\n",
        "We look at the last time cycle for every unit number.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVn0ZdmKDsb0",
        "colab_type": "code",
        "outputId": "5e721177-0131-403a-88d8-0773c81dd367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "train_pd.groupby(['Unit Number'])['Time (Cycles)'].max().hist(bins=30, grid=False)\n",
        "plt.xlabel('Number of Cycles')\n",
        "plt.ylabel('Frequency')\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-6683d01feae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unit Number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time (Cycles)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Cycles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-7vUK4u85DO",
        "colab_type": "text"
      },
      "source": [
        "#**Model 1: Multiple Linear Regression (Not time-sensitive)**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mn7nZq39QVV",
        "colab_type": "text"
      },
      "source": [
        "**Preparing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSvBTo9285u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling data\n",
        "\n",
        "train_pd_scaled = train_pd.copy()\n",
        "train_pd_scaled.iloc[:,2:26] = scaler.fit_transform(train_pd.iloc[:,2:26])\n",
        "\n",
        "test_pd_lm = test_pd.copy()\n",
        "test_pd_lm.iloc[:,2:26] = scaler.fit_transform(test_pd.iloc[:,2:26])\n",
        "\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENkana6AH9LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing RUL and Unit Number columns, as we do not want these features to be in our predictors\n",
        "\n",
        "train_pd_lm = train_pd_scaled.copy()\n",
        "train_pd_lm = train_pd_lm.drop(['RUL', 'Unit Number'],axis=1)\n",
        "\n",
        "# Keeping only last time cycle for each unit number\n",
        "\n",
        "idx = test_pd_lm.groupby(['Unit Number'])['Time (Cycles)'].transform(max) == test_pd_lm['Time (Cycles)']\n",
        "test_pd_lm = test_pd_scaled[idx]\n",
        "\n",
        "# Removing Unit Number column\n",
        "\n",
        "test_pd_lm = test_pd_lm.drop(['Unit Number'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1taB9Kg6Nz_P",
        "colab_type": "text"
      },
      "source": [
        "**Fitting Linear Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvtozoRK9Xxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a3295887-4066-4732-d2e2-28f87bee04d5"
      },
      "source": [
        "# Fitting Linear model\n",
        "\n",
        "reg = LinearRegression().fit(train_pd_lm, y_train)\n",
        "\n",
        "y_pred = reg.predict(test_pd_lm)\n",
        "\n",
        "acc_score_lm =  metrics.mean_squared_error(valid_pd, y_pred)\n",
        "\n",
        "print(f'The square root of the mean squared error for the linear model is: {math.sqrt(acc_score_lm)}.')\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The square root of the mean squared error for the linear model is: 54.8991731927702.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhFj4atfNtGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(adjusted_error(valid_pd, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}