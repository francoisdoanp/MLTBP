{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project-ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francoisdoanp/MLTBP/blob/master/Project_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "23I2qdWI4FFG"
      },
      "source": [
        "# **Machine learning - Final Project**\n",
        "\n",
        "# Turbofan engine degradation dataset (NASA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nOxT0nXc366_"
      },
      "source": [
        "# Data Preparation\n",
        "\n",
        "**Importing necessary packages**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J_GboRpW2F6s",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import sklearn.metrics as metrics\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qw2HZErj35aM"
      },
      "source": [
        "**Importing the Turbofan engine degradation dataset.**\n",
        "\n",
        "**Files are located in the following Github repository: https://github.com/francoisdoanp/MLTBP**\n",
        "\n",
        "We have 4 training datasets, which contains information about one hundred engines, all of the same type. Thus, we will combine the training and test data sets. \n",
        "\n",
        "The training and test sets have 21 columns: ID, Time (Cycles), 3 columns for operational settings and 21 sensor measurements.\n",
        "\n",
        "The training and testing sets have the same format, while the validation sets only contain the real RUL (remaining useful life).\n",
        "\n",
        "For more information on the data, consult the read me at the following address:https://github.com/francoisdoanp/MLTBP/blob/master/readme.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CmZzDVll4vDW",
        "colab": {}
      },
      "source": [
        "url_base = 'https://raw.githubusercontent.com/francoisdoanp/MLTBP/master/'\n",
        "\n",
        "file_train_1 = 'train_FD001.txt'\n",
        "file_train_2 = 'train_FD002.txt'\n",
        "file_train_3 = 'train_FD003.txt'\n",
        "file_train_4 = 'train_FD004.txt'\n",
        "\n",
        "file_test_1 = 'test_FD001.txt'\n",
        "file_test_2 = 'test_FD002.txt'\n",
        "file_test_3 = 'test_FD003.txt'\n",
        "file_test_4 = 'test_FD004.txt'\n",
        "\n",
        "file_valid_1 = 'RUL_FD001.txt'\n",
        "file_valid_2 = 'RUL_FD002.txt'\n",
        "file_valid_3 = 'RUL_FD003.txt'\n",
        "file_valid_4 = 'RUL_FD004.txt'\n",
        "\n",
        "\n",
        "pt1 = pd.read_csv(url_base + file_train_1, sep=' ', header=None)\n",
        "pt2 = pd.read_csv(url_base + file_train_2, sep=' ', header=None)\n",
        "pt3 = pd.read_csv(url_base + file_train_3, sep=' ', header=None)\n",
        "pt4 = pd.read_csv(url_base + file_train_4, sep=' ', header=None)\n",
        "\n",
        "pte1 = pd.read_csv(url_base + file_test_1, sep=' ', header=None)\n",
        "pte2 = pd.read_csv(url_base + file_test_2, sep=' ', header=None)\n",
        "pte3 = pd.read_csv(url_base + file_test_3, sep=' ', header=None)\n",
        "pte4 = pd.read_csv(url_base + file_test_4, sep=' ', header=None)\n",
        "\n",
        "pv1 = pd.read_csv(url_base + file_valid_1, header=None)\n",
        "pv2 = pd.read_csv(url_base + file_valid_2, header=None)\n",
        "pv3 = pd.read_csv(url_base + file_valid_3, header=None)\n",
        "pv4 = pd.read_csv(url_base + file_valid_4, header=None)\n",
        "\n",
        "\n",
        "# Updating ids\n",
        "\n",
        "pt2[0] = pt2[0].apply(lambda x: x+100)\n",
        "pt3[0] = pt3[0].apply(lambda x: x+360)\n",
        "pt4[0] = pt4[0].apply(lambda x: x+460)\n",
        "\n",
        "pte2[0] = pte2[0].apply(lambda x: x+100)\n",
        "pte3[0] = pte3[0].apply(lambda x: x+359)\n",
        "pte4[0] = pte4[0].apply(lambda x: x+459)\n",
        "\n",
        "\n",
        "# Joining the dataframes\n",
        "\n",
        "train_pd = pd.concat([pt1,pt2,pt3,pt4])\n",
        "test_pd = pd.concat([pte1,pte2,pte3,pte4])\n",
        "valid_pd = pd.concat([pv1,pv2,pv3,pv4], ignore_index=True)\n",
        "\n",
        "train_pd = train_pd.drop(train_pd.columns[[26,27]], axis='columns')\n",
        "test_pd = test_pd.drop(test_pd.columns[[26,27]], axis='columns')\n",
        "\n",
        "\n",
        "# Assigning labels to Dataframe's columns based on the Readme\n",
        "\n",
        "train_pd.columns = ['id', 'Time (Cycles)', 'OS1', 'OS2', 'OS3', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21']\n",
        "test_pd.columns = ['id', 'Time (Cycles)', 'OS1', 'OS2', 'OS3', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S17', 'S18', 'S19', 'S20', 'S21']\n",
        "valid_pd.columns = ['RUL']\n",
        "\n",
        "#Loading scaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G9va4qroPgeB"
      },
      "source": [
        "**Adding variables Conditons and fault mode**\n",
        "\n",
        "Note:\n",
        "\n",
        "**Condition (ONE)** and **Fault ONE** are binary variables.\n",
        "\n",
        "When Condition(ONE) = 1 (true), it means that the condition is at Sea Level\n",
        "\n",
        "When Condition(ONE) = 0 (false), it means NO, the condition IS NOT AT SEA LEVEL, and thus is the  second condition; SIX.\n",
        "\n",
        "When Fault ONE = 1 (true), it means that the fault modes is one (HPC Degradation)\n",
        "\n",
        "When Fault ONE = 0 (false), it means that the fault mode is TWO (HPC Degradation and Fan degradation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_WQaAK97PfZU",
        "outputId": "617f6e15-3c50-4b17-cb38-e0b7c4ada554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Adding variables Condition and fault modes\n",
        "\n",
        "def value_condition_train(row):\n",
        "  if (row['id'] <= 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 360) & (row['id'] > 100):\n",
        "    return 0\n",
        "  elif (row['id'] <= 460) & (row['id'] > 360):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_fault_train(row):\n",
        "  if (row['id'] <= 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 360) & (row['id'] > 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 460) & (row['id'] > 360):\n",
        "    return 0\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_condition_test(row):\n",
        "  if (row['id'] <= 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 359) & (row['id'] > 100):\n",
        "    return 0\n",
        "  elif (row['id'] <= 459) & (row['id'] > 359):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "def value_fault_test(row):\n",
        "  if (row['id'] <= 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 359) & (row['id'] > 100):\n",
        "    return 1\n",
        "  elif (row['id'] <= 459) & (row['id'] > 359):\n",
        "    return 0\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "train_pd['Condition (One)'] = train_pd.apply(value_condition_train, axis=1)\n",
        "train_pd['Fault ONE'] = train_pd.apply(value_fault_train,axis=1)\n",
        "\n",
        "test_pd['Condition (One)'] = test_pd.apply(value_condition_test, axis=1)\n",
        "test_pd['Fault ONE'] = test_pd.apply(value_fault_test,axis=1)\n",
        "\n",
        "display(train_pd)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Time (Cycles)</th>\n",
              "      <th>OS1</th>\n",
              "      <th>OS2</th>\n",
              "      <th>OS3</th>\n",
              "      <th>S1</th>\n",
              "      <th>S2</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>S5</th>\n",
              "      <th>S6</th>\n",
              "      <th>S7</th>\n",
              "      <th>S8</th>\n",
              "      <th>S9</th>\n",
              "      <th>S10</th>\n",
              "      <th>S11</th>\n",
              "      <th>S12</th>\n",
              "      <th>S13</th>\n",
              "      <th>S14</th>\n",
              "      <th>S15</th>\n",
              "      <th>S16</th>\n",
              "      <th>S17</th>\n",
              "      <th>S18</th>\n",
              "      <th>S19</th>\n",
              "      <th>S20</th>\n",
              "      <th>S21</th>\n",
              "      <th>Condition (One)</th>\n",
              "      <th>Fault ONE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>0.03</td>\n",
              "      <td>390</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>0.03</td>\n",
              "      <td>392</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.61</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>1.30</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>0.03</td>\n",
              "      <td>393</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61244</th>\n",
              "      <td>709</td>\n",
              "      <td>251</td>\n",
              "      <td>9.9998</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>100.0</td>\n",
              "      <td>489.05</td>\n",
              "      <td>605.33</td>\n",
              "      <td>1516.36</td>\n",
              "      <td>1315.28</td>\n",
              "      <td>10.52</td>\n",
              "      <td>15.46</td>\n",
              "      <td>404.59</td>\n",
              "      <td>2319.66</td>\n",
              "      <td>8840.16</td>\n",
              "      <td>1.27</td>\n",
              "      <td>46.08</td>\n",
              "      <td>380.16</td>\n",
              "      <td>2388.73</td>\n",
              "      <td>8185.69</td>\n",
              "      <td>8.4541</td>\n",
              "      <td>0.03</td>\n",
              "      <td>372</td>\n",
              "      <td>2319</td>\n",
              "      <td>100.0</td>\n",
              "      <td>29.11</td>\n",
              "      <td>17.5234</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61245</th>\n",
              "      <td>709</td>\n",
              "      <td>252</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.42</td>\n",
              "      <td>1598.92</td>\n",
              "      <td>1426.77</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.57</td>\n",
              "      <td>567.59</td>\n",
              "      <td>2388.47</td>\n",
              "      <td>9117.12</td>\n",
              "      <td>1.31</td>\n",
              "      <td>48.04</td>\n",
              "      <td>535.02</td>\n",
              "      <td>2388.46</td>\n",
              "      <td>8185.47</td>\n",
              "      <td>8.2221</td>\n",
              "      <td>0.03</td>\n",
              "      <td>396</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.38</td>\n",
              "      <td>23.7151</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61246</th>\n",
              "      <td>709</td>\n",
              "      <td>253</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>518.67</td>\n",
              "      <td>643.68</td>\n",
              "      <td>1607.72</td>\n",
              "      <td>1430.56</td>\n",
              "      <td>14.62</td>\n",
              "      <td>21.57</td>\n",
              "      <td>569.04</td>\n",
              "      <td>2388.51</td>\n",
              "      <td>9126.53</td>\n",
              "      <td>1.31</td>\n",
              "      <td>48.24</td>\n",
              "      <td>535.41</td>\n",
              "      <td>2388.48</td>\n",
              "      <td>8193.94</td>\n",
              "      <td>8.2525</td>\n",
              "      <td>0.03</td>\n",
              "      <td>395</td>\n",
              "      <td>2388</td>\n",
              "      <td>100.0</td>\n",
              "      <td>39.78</td>\n",
              "      <td>23.8270</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61247</th>\n",
              "      <td>709</td>\n",
              "      <td>254</td>\n",
              "      <td>35.0046</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>449.44</td>\n",
              "      <td>555.77</td>\n",
              "      <td>1381.29</td>\n",
              "      <td>1148.18</td>\n",
              "      <td>5.48</td>\n",
              "      <td>7.96</td>\n",
              "      <td>199.93</td>\n",
              "      <td>2223.78</td>\n",
              "      <td>8403.64</td>\n",
              "      <td>1.05</td>\n",
              "      <td>42.53</td>\n",
              "      <td>187.92</td>\n",
              "      <td>2388.83</td>\n",
              "      <td>8125.64</td>\n",
              "      <td>9.0515</td>\n",
              "      <td>0.02</td>\n",
              "      <td>337</td>\n",
              "      <td>2223</td>\n",
              "      <td>100.0</td>\n",
              "      <td>15.26</td>\n",
              "      <td>9.0774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61248</th>\n",
              "      <td>709</td>\n",
              "      <td>255</td>\n",
              "      <td>42.0030</td>\n",
              "      <td>0.8400</td>\n",
              "      <td>100.0</td>\n",
              "      <td>445.00</td>\n",
              "      <td>549.85</td>\n",
              "      <td>1369.75</td>\n",
              "      <td>1147.45</td>\n",
              "      <td>3.91</td>\n",
              "      <td>5.69</td>\n",
              "      <td>142.47</td>\n",
              "      <td>2212.52</td>\n",
              "      <td>8391.31</td>\n",
              "      <td>1.05</td>\n",
              "      <td>42.60</td>\n",
              "      <td>134.32</td>\n",
              "      <td>2388.66</td>\n",
              "      <td>8144.33</td>\n",
              "      <td>9.1207</td>\n",
              "      <td>0.02</td>\n",
              "      <td>333</td>\n",
              "      <td>2212</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.66</td>\n",
              "      <td>6.4341</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>160359 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  Time (Cycles)      OS1  ...      S21  Condition (One)  Fault ONE\n",
              "0        1              1  -0.0007  ...  23.4190                1          1\n",
              "1        1              2   0.0019  ...  23.4236                1          1\n",
              "2        1              3  -0.0043  ...  23.3442                1          1\n",
              "3        1              4   0.0007  ...  23.3739                1          1\n",
              "4        1              5  -0.0019  ...  23.4044                1          1\n",
              "...    ...            ...      ...  ...      ...              ...        ...\n",
              "61244  709            251   9.9998  ...  17.5234                0          0\n",
              "61245  709            252   0.0028  ...  23.7151                0          0\n",
              "61246  709            253   0.0029  ...  23.8270                0          0\n",
              "61247  709            254  35.0046  ...   9.0774                0          0\n",
              "61248  709            255  42.0030  ...   6.4341                0          0\n",
              "\n",
              "[160359 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lAl6DjVwhdhU"
      },
      "source": [
        "At this stage, we create the truth remaining useful life (RUL) for the training set.\n",
        "\n",
        "Important note: In the training set, the last Cycle (represented in the table by 'Time (Cycles)') is when the engine is considered unusable. However, in the test set, the last cycle IS NOT when the engine is considered unusable. It will fail at a later time. Thus, in the valid_pd, we have the true RUL. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UdbuXXApd51H",
        "colab": {}
      },
      "source": [
        "#Adding column for remaining useful life (RUL)\n",
        "\n",
        "y_train = pd.DataFrame(train_pd.groupby(['id'])['Time (Cycles)'].max())\n",
        "\n",
        "train_pd = pd.merge(train_pd,y_train, on='id')\n",
        "train_pd['RUL'] = train_pd['Time (Cycles)_y'] - train_pd['Time (Cycles)_x']\n",
        "train_pd = train_pd.drop('Time (Cycles)_y',1)\n",
        "train_pd = train_pd.rename(columns = {'Time (Cycles)_x':'Time (Cycles)'})\n",
        "\n",
        "y_train = train_pd.iloc[:,28]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vhz30Roasqsx",
        "colab": {}
      },
      "source": [
        "def model_score(y_true, y_pred):\n",
        "  pred_df = pd.DataFrame(y_pred)\n",
        "  test_err = pd.concat([y_true,pred_df], axis=1)\n",
        "  test_err.columns = ['RUL', 'Pred_RUL']\n",
        "  a1 = 10\n",
        "  a2 = 13\n",
        "  score=0\n",
        "\n",
        "  for index, row in test_err.iterrows():\n",
        "    d = row['Pred_RUL'] - row['RUL']\n",
        "    if d < 0:\n",
        "      score += np.expm1(-(d/a1))\n",
        "    else:\n",
        "      score += np.expm1(d/a2)\n",
        "\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IBSnn8dg_S-f"
      },
      "source": [
        "\n",
        "# Data Exploration\n",
        "\n",
        "**Now that we have our data, we can get to know our dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gLyYj7yG_O7J",
        "colab": {}
      },
      "source": [
        "display(train_pd.head())\n",
        "\n",
        "display(test_pd)\n",
        "\n",
        "\n",
        "print(f'The training dataset contains {train_pd.shape[0]} rows.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MolsPcwA8oH2",
        "colab": {}
      },
      "source": [
        "# Print out a table with count, mean, std, min, max, 25%, 50%, 75%\n",
        "\n",
        "print(train_pd.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e9NjbN8Ul_QA"
      },
      "source": [
        "**Exploring the effects of sensors on RUL**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5gRZJbxko0zO",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "print(sns.heatmap(train_pd.corr(), annot=True, cmap='RdYlGn'))\n",
        "\n",
        "train_pd.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kg9ioWTZpt4c",
        "colab": {}
      },
      "source": [
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xk-xi71-oicW"
      },
      "source": [
        "**Exploring correlation between variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vqocxW0Qohvj",
        "colab": {}
      },
      "source": [
        "corr = train_pd.groupby(['RUL']).corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rd8Y35kaDfly"
      },
      "source": [
        "**How do we know when an engine fails?**\n",
        "\n",
        "We look at the last time cycle for every id.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uVn0ZdmKDsb0",
        "colab": {}
      },
      "source": [
        "train_pd.groupby(['id'])['Time (Cycles)'].max().hist(bins=30, grid=False)\n",
        "plt.xlabel('Number of Cycles')\n",
        "plt.ylabel('Frequency')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n-7vUK4u85DO"
      },
      "source": [
        "#**Model 1: Multiple Linear Regression**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-mn7nZq39QVV"
      },
      "source": [
        "**Preparing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSvBTo9285u0",
        "colab": {}
      },
      "source": [
        "# Scaling data\n",
        "\n",
        "train_pd_scaled = train_pd.copy()\n",
        "train_pd_scaled.iloc[:,2:26] = scaler.fit_transform(train_pd.iloc[:,2:26])\n",
        "\n",
        "test_pd_scaled = test_pd.copy()\n",
        "test_pd_scaled.iloc[:,2:26] = scaler.fit_transform(test_pd.iloc[:,2:26])\n",
        "\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.max_colwidth', -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ENkana6AH9LA",
        "colab": {}
      },
      "source": [
        "# Removing RUL and id columns, as we do not want these features to be in our predictors\n",
        "\n",
        "train_pd_lm = train_pd_scaled.copy()\n",
        "train_pd_lm = train_pd_lm.drop(['id', 'RUL'],axis=1)\n",
        "\n",
        "# Keeping only last time cycle for each id\n",
        "\n",
        "idx = test_pd_scaled.groupby(['id'])['Time (Cycles)'].transform(max) == test_pd_scaled['Time (Cycles)']\n",
        "test_pd_lm = test_pd_scaled[idx]\n",
        "\n",
        "# Removing id column\n",
        "\n",
        "test_pd_lm = test_pd_lm.drop(['id'], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1taB9Kg6Nz_P"
      },
      "source": [
        "**Fitting Linear Model (Not time sensitive)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FvtozoRK9Xxj",
        "outputId": "fa09ebf1-d8c7-483d-c869-d14404a312db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Fitting Linear model\n",
        "\n",
        "reg = LinearRegression().fit(train_pd_lm, y_train)\n",
        "\n",
        "y_pred = reg.predict(test_pd_lm)\n",
        "\n",
        "acc_score_lm =  metrics.mean_absolute_error(valid_pd, y_pred)\n",
        "\n",
        "print(f'The mean absolute error for the linear model is: {(acc_score_lm)}.')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean absolute error for the linear model is: 44.965450059476375.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx7pJ2iVgTwi",
        "colab_type": "text"
      },
      "source": [
        "**Linear Model with interactions & Polynomial**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0rRYfxNhg3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The PolynomialFeatures transforms our dataset to include ALL interactions and ALL variables^2.\n",
        "\n",
        "lm_poly_int = PolynomialFeatures(2)\n",
        "train_pd_lm_poly = lm_poly_int.fit_transform(train_pd_lm)\n",
        "\n",
        "reg_poly = LinearRegression().fit(train_pd_lm_poly,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSJhNHznjrlb",
        "colab_type": "code",
        "outputId": "92807f6d-afb9-4a29-ad91-03e0bb9e0b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test_pd_lm_poly = lm_poly_int.fit_transform(test_pd_lm)\n",
        "\n",
        "y_pred_poly = reg_poly.predict(test_pd_lm_poly)\n",
        "\n",
        "acc_score_lm_poly =  metrics.mean_absolute_error(valid_pd, y_pred_poly)\n",
        "\n",
        "print(f'The mean absolute error for the linear model is: {(acc_score_lm_poly)}.')\n",
        "\n",
        "# We conclude that there is probabily high colinearity in the variables, so a model including interactions would not help much."
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean absolute error for the linear model is: 6690.860898272314.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhYn-0V5kSw9",
        "colab_type": "text"
      },
      "source": [
        "# **Model 3: Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFTyU01LH4SK",
        "colab_type": "text"
      },
      "source": [
        "# **Model 3.1: Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvWvliCAHwKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "a557b707-5681-4717-ce8d-3ba509a3f79b"
      },
      "source": [
        "# Building Model\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(100,  activation='relu', input_shape=[len(train_pd_lm.keys())], kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01),  activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "model2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.01), activity_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "model2.add(Dense(1))\n",
        "\n",
        "model2.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "\n",
        "print(model2.summary())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_55 (Dense)             (None, 100)               2800      \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 103,901\n",
            "Trainable params: 103,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2XwNbZeKOlv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "97a9efe2-d13f-4906-8fff-fd2c6d14dc81"
      },
      "source": [
        "# Fitting model\n",
        "\n",
        "NNmodel2 = model2.fit(train_pd_lm, y_train, epochs=100, batch_size=200, validation_split=0.05, verbose=1,callbacks =[keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='min')])\n",
        "#NNmodel2 = model2.fit(train_pd_lm, y_train, epochs=10, batch_size=200, validation_split=0.05, verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 152341 samples, validate on 8018 samples\n",
            "Epoch 1/100\n",
            "152341/152341 [==============================] - 7s 45us/step - loss: 11494.4032 - mean_absolute_error: 55.0218 - val_loss: 4431.1032 - val_mean_absolute_error: 41.2999\n",
            "Epoch 2/100\n",
            "152341/152341 [==============================] - 6s 38us/step - loss: 4618.5706 - mean_absolute_error: 44.3435 - val_loss: 3514.9740 - val_mean_absolute_error: 40.2880\n",
            "Epoch 3/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 4010.1143 - mean_absolute_error: 42.7112 - val_loss: 3973.0281 - val_mean_absolute_error: 47.0076\n",
            "Epoch 4/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 3704.9102 - mean_absolute_error: 41.5969 - val_loss: 2891.8027 - val_mean_absolute_error: 37.0188\n",
            "Epoch 5/100\n",
            "152341/152341 [==============================] - 6s 38us/step - loss: 3450.3497 - mean_absolute_error: 40.3535 - val_loss: 2868.2882 - val_mean_absolute_error: 38.2413\n",
            "Epoch 6/100\n",
            "152341/152341 [==============================] - 6s 39us/step - loss: 3287.0193 - mean_absolute_error: 39.4807 - val_loss: 3933.5932 - val_mean_absolute_error: 48.3510\n",
            "Epoch 7/100\n",
            "152341/152341 [==============================] - 6s 38us/step - loss: 3141.0499 - mean_absolute_error: 38.6882 - val_loss: 2544.8091 - val_mean_absolute_error: 35.9689\n",
            "Epoch 8/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 3049.3634 - mean_absolute_error: 38.1186 - val_loss: 2868.2592 - val_mean_absolute_error: 40.8205\n",
            "Epoch 9/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 2950.9309 - mean_absolute_error: 37.5631 - val_loss: 2563.0452 - val_mean_absolute_error: 37.1905\n",
            "Epoch 10/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 2891.0128 - mean_absolute_error: 37.2629 - val_loss: 2250.4276 - val_mean_absolute_error: 33.4273\n",
            "Epoch 11/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 2830.2703 - mean_absolute_error: 36.9298 - val_loss: 3201.2478 - val_mean_absolute_error: 43.6433\n",
            "Epoch 12/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 2780.9195 - mean_absolute_error: 36.5799 - val_loss: 2423.5614 - val_mean_absolute_error: 35.7586\n",
            "Epoch 13/100\n",
            "152341/152341 [==============================] - 6s 38us/step - loss: 2732.6876 - mean_absolute_error: 36.3566 - val_loss: 2442.5331 - val_mean_absolute_error: 35.7458\n",
            "Epoch 14/100\n",
            "152341/152341 [==============================] - 6s 37us/step - loss: 2700.2834 - mean_absolute_error: 36.0308 - val_loss: 2843.8998 - val_mean_absolute_error: 41.2905\n",
            "Epoch 15/100\n",
            "152341/152341 [==============================] - 6s 42us/step - loss: 2660.6941 - mean_absolute_error: 35.8431 - val_loss: 2650.7150 - val_mean_absolute_error: 39.6974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4atglFkEHw50",
        "colab_type": "text"
      },
      "source": [
        "# **Model 3.2: Reccurent Neural Network with LSTM architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YhFj4atfNtGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a89da105-8b9d-435f-d18e-4b8743057cb5"
      },
      "source": [
        "# Using Azure tutorial for predictive maintenance for data manipulation\n",
        "# Reference: https://github.com/Azure/lstms_for_predictive_maintenance/blob/master/Deep%20Learning%20Basics%20for%20Predictive%20Maintenance.ipynb\n",
        "\n",
        "# Picking a sequence length - This will be the window of time in which the LSTM will gather data from\n",
        "\n",
        "sequence_length = 50\n",
        "\n",
        "\n",
        "# This function will reshape our data so it can be usable with Keras (Samples, time window, features)\n",
        "def gen_sequence(id_df, seq_length,seq_cols):\n",
        "  data_array = id_df[seq_cols].values\n",
        "  num_elements = data_array.shape[0]\n",
        "  for start,stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "    yield data_array[start:stop,:]\n",
        "\n",
        "# Reference column names\n",
        "\n",
        "sensor_cols = ['S' + str(i) for i in range(1,22)]\n",
        "sequence_cols = ['Time (Cycles)', 'OS1', 'OS2', 'OS3']\n",
        "other_cols = ['Condition (One)', 'Fault ONE']\n",
        "sequence_cols.extend(sensor_cols)\n",
        "sequence_cols.extend(other_cols)\n",
        "\n",
        "# Generating sequences\n",
        "\n",
        "seq_gen = (list(gen_sequence(train_pd_scaled[train_pd_scaled['id']==id], sequence_length,sequence_cols))\n",
        "          for id in train_pd_scaled['id'].unique())\n",
        "\n",
        "# Generate sequences and convert to numpy array\n",
        "\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "print(seq_array.shape)\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "  data = id_df[label].values\n",
        "  num_elements = data.shape[0]\n",
        "  return data[seq_length:num_elements,:]\n",
        "\n",
        "label_gen = [gen_labels(train_pd_scaled[train_pd_scaled['id']==id], sequence_length, ['RUL'])\n",
        "            for id in train_pd_scaled['id'].unique()]\n",
        "\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "print(seq_gen)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(124909, 50, 27)\n",
            "<generator object <genexpr> at 0x7f4bede5dba0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7CzDE0PV9a0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "949cba13-33de-49b0-8e5e-68d43e32396b"
      },
      "source": [
        "# Building the RNN\n",
        "\n",
        "nb_features = seq_array.shape[2]\n",
        "nb_out = label_array.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(input_shape=(sequence_length, nb_features), units=100, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(input_shape=(sequence_length, nb_features), units=50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=nb_out))\n",
        "model.add(Activation('linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 50, 100)           51200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 1)                 51        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 81,451\n",
            "Trainable params: 81,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhCTv_y1dYxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "9afc6f71-0341-4b1e-f866-549bcb07c61c"
      },
      "source": [
        "# Fitting the RNN\n",
        "\n",
        "NNmodel = model.fit(seq_array, label_array, epochs=100, batch_size=200, validation_split=0.05, verbose=1, callbacks =[keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 118663 samples, validate on 6246 samples\n",
            "Epoch 1/100\n",
            "118663/118663 [==============================] - 180s 2ms/step - loss: 11263.6000 - mean_absolute_error: 79.7464 - val_loss: 9381.0478 - val_mean_absolute_error: 73.6410\n",
            "Epoch 2/100\n",
            "118663/118663 [==============================] - 178s 1ms/step - loss: 7606.8498 - mean_absolute_error: 63.1650 - val_loss: 6331.0122 - val_mean_absolute_error: 60.2269\n",
            "Epoch 3/100\n",
            "118663/118663 [==============================] - 178s 1ms/step - loss: 5496.2044 - mean_absolute_error: 53.1984 - val_loss: 4953.3979 - val_mean_absolute_error: 55.6433\n",
            "Epoch 4/100\n",
            "118663/118663 [==============================] - 179s 2ms/step - loss: 4173.1515 - mean_absolute_error: 45.7890 - val_loss: 3799.5020 - val_mean_absolute_error: 49.5679\n",
            "Epoch 5/100\n",
            "118663/118663 [==============================] - 180s 2ms/step - loss: 3458.4496 - mean_absolute_error: 41.6263 - val_loss: 3811.0235 - val_mean_absolute_error: 51.5891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWRJI83J1R67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding RUL to test set\n",
        "\n",
        "truth_nn= valid_pd.copy()\n",
        "max_hid = pd.DataFrame(test_pd.groupby('id')['Time (Cycles)'].max()).reset_index()\n",
        "max_hid.columns = ['id','max']\n",
        "truth_nn.columns = ['truth']\n",
        "truth_nn['id'] = truth_nn.index +1\n",
        "truth_nn['truth'] = truth_nn['truth'] + max_hid['max']\n",
        "\n",
        "test_pd_nn = test_pd.copy()\n",
        "test_pd_nn = test_pd_nn.merge(truth_nn, on=['id'], how='left')\n",
        "test_pd_nn['RUL'] = test_pd_nn['truth'] - test_pd_nn['Time (Cycles)']\n",
        "test_pd_nn.drop('truth', axis=1, inplace=True)\n",
        "\n",
        "print(test_pd_nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCjYCkhVvv_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "c3cd21d3-c3d9-473f-ae53-b94b134a705a"
      },
      "source": [
        "# Testing performance on test set\n",
        "\n",
        "seq_array_test = [test_pd_nn[test_pd_nn['id']==id][sequence_cols].values[-sequence_length:]\n",
        "                 for id in test_pd_nn['id'].unique() if len(test_pd_nn[test_pd_nn['id']==id]) >= sequence_length]\n",
        "\n",
        "seq_array_test = np.asarray(seq_array_test).astype(np.float32)\n",
        "\n",
        "y_mask = [len(test_pd_nn[test_pd_nn['id']==id]) >= sequence_length for id in test_pd_nn['id'].unique()]\n",
        "\n",
        "label_array_test = test_pd_nn.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
        "label_array_test = label_array_test.reshape(label_array_test.shape[0],1).astype(np.float32)\n",
        "\n",
        "print(seq_array_test.shape)\n",
        "print(label_aray_test.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-74460d9e2b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlabel_array_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pd_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RUL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlabel_array_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabal_array_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_array_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_array_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labal_array_test' is not defined"
          ]
        }
      ]
    }
  ]
}